{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1OzxjU4ZZW5OqqG4BcjVM8kk2PRwnJ3Qj","authorship_tag":"ABX9TyOWyeKIpHOY/Y8iVnM5ZHlD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Instalar PySpark\n","!pip -q install pyspark==3.5.1\n","\n","# Montar o Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Caminho base do projeto (pasta Eixo_05)\n","base_path = \"/content/drive/MyDrive/Eixo_05/dados/\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WNAAltRQSZ6V","executionInfo":{"status":"ok","timestamp":1760103017740,"user_tz":-60,"elapsed":11167,"user":{"displayName":"Ravi Ferreira Pellizzi","userId":"04678001779669650850"}},"outputId":"e20898d0-46fa-42d8-a3bd-7f265ead5693"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Iniciar sessão Spark\n","from pyspark.sql import SparkSession\n","\n","spark = (\n","    SparkSession.builder\n","    .appName(\"imdb-processamento\")\n","    .getOrCreate()\n",")\n","spark\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"hdjUSVdlP7DX","executionInfo":{"status":"ok","timestamp":1760103037576,"user_tz":-60,"elapsed":19830,"user":{"displayName":"Ravi Ferreira Pellizzi","userId":"04678001779669650850"}},"outputId":"2beb8cf2-2b73-4049-805d-e0234e14e59f"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x78d0a233fa10>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://3e40fcf0e91b:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.5.1</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>imdb-processamento</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["# Imports necessários\n","from pyspark.sql.functions import col, lower, regexp_replace\n","from pyspark.ml.feature import (\n","    StringIndexer, RegexTokenizer, StopWordsRemover,\n","    HashingTF, IDF, Word2Vec, MinMaxScaler\n",")\n","\n","# Função auxiliar para valores nulos\n","def calcula_valores_nulos(df):\n","    null_columns_counts = []\n","    numRows = df.count()\n","    for k in df.columns:\n","        nullRows = df.where(col(k).isNull()).count()\n","        if nullRows > 0:\n","            null_columns_counts.append((k, nullRows, (nullRows / numRows) * 100))\n","    return null_columns_counts\n"],"metadata":{"id":"F5gsGXtAP_X0","executionInfo":{"status":"ok","timestamp":1760103038318,"user_tz":-60,"elapsed":739,"user":{"displayName":"Ravi Ferreira Pellizzi","userId":"04678001779669650850"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Função principal de limpeza e transformação\n","def limpar_transformar(spark, base_path):\n","    # 1) Ler o CSV salvo no Drive\n","    #reviews = spark.read.csv(base_path + \"dataset.csv\", header=True, escape=\"\\\"\").limit(5000)\n","    reviews = spark.read.csv(base_path + \"dataset.csv\", header=True, escape=\"\\\"\")\n","\n","    # 2) Tratar valores nulos\n","    nulos = calcula_valores_nulos(reviews)\n","    if nulos:\n","        reviews = reviews.dropna()\n","\n","    # 3) Indexar rótulos (sentiment -> label)\n","    indexer = StringIndexer(inputCol=\"sentiment\", outputCol=\"label\")\n","    df = indexer.fit(reviews).transform(reviews)\n","\n","    # 4) Limpeza de texto\n","    df = df.withColumn(\"review\", regexp_replace(col(\"review\"), '<.*/>', ''))\n","    df = df.withColumn(\"review\", regexp_replace(col(\"review\"), '[^A-Za-z ]+', ''))\n","    df = df.withColumn(\"review\", regexp_replace(col(\"review\"), ' +', ' '))\n","    df = df.withColumn(\"review\", lower(col(\"review\")))\n","\n","    # 5) Tokenização e remoção de stopwords\n","    df = RegexTokenizer(inputCol=\"review\", outputCol=\"words\", pattern=\"\\\\W\").transform(df)\n","    feature_data = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").transform(df)\n","\n","    # 6) HashingTF\n","    htf = HashingTF(inputCol=\"filtered\", outputCol=\"rawfeatures\", numFeatures=250)\n","    HTFfeaturizedData = htf.transform(feature_data)\n","\n","    # 7) TF-IDF\n","    idf = IDF(inputCol=\"rawfeatures\", outputCol=\"features\")\n","    idfModel = idf.fit(HTFfeaturizedData)\n","    TFIDFfeaturizedData = idfModel.transform(HTFfeaturizedData)\n","\n","    # 8) Word2Vec + MinMaxScaler\n","    w2v = Word2Vec(vectorSize=250, minCount=5, inputCol=\"filtered\", outputCol=\"features\")\n","    W2VfeaturizedData = w2v.fit(feature_data).transform(feature_data)\n","\n","    scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n","    scaled = scaler.fit(W2VfeaturizedData).transform(W2VfeaturizedData)\n","    W2VfeaturizedData = scaled.select(\"sentiment\", \"review\", \"label\", \"scaledFeatures\") \\\n","                              .withColumnRenamed(\"scaledFeatures\", \"features\")\n","\n","    # 9) Salvar resultados no Drive\n","    (HTFfeaturizedData\n","     .select(\"sentiment\", \"review\", \"label\", \"rawfeatures\")\n","     .withColumnRenamed(\"rawfeatures\", \"features\")\n","     .write.mode(\"overwrite\").parquet(base_path + \"HTFfeaturizedData\"))\n","\n","    TFIDFfeaturizedData.select(\"sentiment\", \"review\", \"label\", \"features\") \\\n","        .write.mode(\"overwrite\").parquet(base_path + \"TFIDFfeaturizedData\")\n","\n","    W2VfeaturizedData.select(\"sentiment\", \"review\", \"label\", \"features\") \\\n","        .write.mode(\"overwrite\").parquet(base_path + \"W2VfeaturizedData\")\n","\n","    return (\n","        HTFfeaturizedData.select(\"sentiment\", \"review\", \"label\", \"rawfeatures\")\n","                         .withColumnRenamed(\"rawfeatures\", \"features\"),\n","        TFIDFfeaturizedData.select(\"sentiment\", \"review\", \"label\", \"features\"),\n","        W2VfeaturizedData.select(\"sentiment\", \"review\", \"label\", \"features\"),\n","    )\n"],"metadata":{"id":"YEL2PHrpQBXE","executionInfo":{"status":"ok","timestamp":1760103038324,"user_tz":-60,"elapsed":8,"user":{"displayName":"Ravi Ferreira Pellizzi","userId":"04678001779669650850"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Executar processamento e salvar resultados no Drive\n","HTF, TFIDF, W2V = limpar_transformar(spark, base_path=base_path)\n","\n","print(\"Dados processados e salvos no Google Drive em:\")\n","print(f\"{base_path}HTFfeaturizedData\")\n","print(f\"{base_path}TFIDFfeaturizedData\")\n","print(f\"{base_path}W2VfeaturizedData\")\n","\n","print(\"Contagens:\", HTF.count(), TFIDF.count(), W2V.count())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JxytZdn-QFkb","executionInfo":{"status":"ok","timestamp":1760103448157,"user_tz":-60,"elapsed":409829,"user":{"displayName":"Ravi Ferreira Pellizzi","userId":"04678001779669650850"}},"outputId":"15575742-369a-442b-8695-abe2948138a6"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Dados processados e salvos no Google Drive em:\n","/content/drive/MyDrive/Eixo_05/dados/HTFfeaturizedData\n","/content/drive/MyDrive/Eixo_05/dados/TFIDFfeaturizedData\n","/content/drive/MyDrive/Eixo_05/dados/W2VfeaturizedData\n","Contagens: 50000 50000 50000\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Spiq_dGCQGis","executionInfo":{"status":"ok","timestamp":1760103448184,"user_tz":-60,"elapsed":16,"user":{"displayName":"Ravi Ferreira Pellizzi","userId":"04678001779669650850"}}},"execution_count":5,"outputs":[]}]}